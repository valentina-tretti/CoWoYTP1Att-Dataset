{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Binary Classification with BETO\n",
        " * Classification of comments as related and not related to the video content\n",
        " * Classes: 1. yes (comment is related to the video or its content), and 2. no (comment is not related to the video or its content)."
      ],
      "metadata": {
        "id": "kI4ScjPu4GL-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Requirements"
      ],
      "metadata": {
        "id": "6JYVmnYeCFfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch transformers datasets"
      ],
      "metadata": {
        "id": "bh9KCxkH_DNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install num2words torch"
      ],
      "metadata": {
        "id": "yD4VIgny_CgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download es_core_news_sm"
      ],
      "metadata": {
        "id": "5IOn-Jfl_Edc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import seaborn as sns\n",
        "import copy\n",
        "import warnings\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "import spacy\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "from torch.utils.data import DataLoader\n",
        "from datasets import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from num2words import num2words\n",
        "from datasets import load_dataset\n",
        "from transformers import BertModel,BertTokenizer, TrainingArguments, Trainer, AutoConfig\n",
        "from torch.optim import AdamW\n",
        "from torch.nn import CrossEntropyLoss"
      ],
      "metadata": {
        "id": "Oogp_Eq44TVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "GpM3-MLB4pAv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For preprocessing use ***Preprocessing.ipynb script***"
      ],
      "metadata": {
        "id": "atVrdvvPDyWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading preprocessed data\n",
        "data = pd.read_csv(\"sample_Task1.csv\") # change to sample_Task2.csv for experiment 2\n",
        "dataD_copy = data.copy() # creating copy of data file"
      ],
      "metadata": {
        "id": "h4ikwywf40NR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing rows with Nan values and with only one character"
      ],
      "metadata": {
        "id": "IEMBzM0Z42iT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing rows with nan values\n",
        "dataD_copy.dropna(subset=[\"comment_cleaned\"], inplace=True)\n",
        "\n",
        "# Removing rows with only one character\n",
        "def filter_comments(text):\n",
        "    if not isinstance(text, str):  # skip if NaN or non-string\n",
        "        return False\n",
        "    tokens = text.split()\n",
        "    # Condition 1: only one character (ignoring spaces)\n",
        "    if len(text.strip()) == 1:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "dataD_copy = dataD_copy[dataD_copy['comment_cleaned'].apply(filter_comments)]"
      ],
      "metadata": {
        "id": "Vp4Z6ff04019"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataD_copy.columns"
      ],
      "metadata": {
        "id": "hzJgDFpK-br0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Splitting datasets"
      ],
      "metadata": {
        "id": "geFdqrhF5Jva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_mapping = {\"yes\": 0, \"no\": 1}\n",
        "dataD_copy['label'] = dataD_copy['related_video'].map(label_mapping)\n",
        "dataD_copy['label'].value_counts()"
      ],
      "metadata": {
        "id": "TaDf31Z--YvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split ratios\n",
        "train_ratio = 0.75\n",
        "validation_ratio = 0.15\n",
        "test_ratio = 0.10\n",
        "\n",
        "# First split: train and temp (val + test)\n",
        "df_train, df_temp = train_test_split(dataD_copy, test_size=(1 - train_ratio), random_state=42)\n",
        "\n",
        "# Second split: validation and test from df_temp\n",
        "# Compute relative proportions\n",
        "val_size = validation_ratio / (validation_ratio + test_ratio)\n",
        "\n",
        "df_val, df_test = train_test_split(df_temp, test_size=(1 - val_size), random_state=42)\n",
        "\n",
        "# Check size distribution (optional)\n",
        "print(f\"Train size: {len(df_train)}\")\n",
        "print(f\"Validation size: {len(df_val)}\")\n",
        "print(f\"Test size: {len(df_test)}\")\n"
      ],
      "metadata": {
        "id": "Tl7aKBpf_A2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Droping id column in dataframes\n",
        "for df_split in [df_train, df_val, df_test]:\n",
        "  df_split.drop(columns=['id'], inplace=True)"
      ],
      "metadata": {
        "id": "3gDn0mQl6-zA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting datasets into Hugging Face Dataset format\n",
        "train_set = Dataset.from_pandas(df_train)\n",
        "val_set = Dataset.from_pandas(df_val)\n",
        "test_set = Dataset.from_pandas(df_test)"
      ],
      "metadata": {
        "id": "pqOSLHKd5JNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing '__index_level_0__' form datasets\n",
        "train_set = train_set.remove_columns(['__index_level_0__'])\n",
        "val_set = val_set.remove_columns(['__index_level_0__'])\n",
        "test_set = test_set.remove_columns(['__index_level_0__'])"
      ],
      "metadata": {
        "id": "BmdKQj_W6Yp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Model\n",
        "* Using transformer BERT based model - BETO\n",
        "* More information available at: https://github.com/dccuchile/beto"
      ],
      "metadata": {
        "id": "qBc80KnF72Ey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "b4fIpCly70Ss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading tokenizerf\n",
        "tokenizer = BertTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-uncased\")"
      ],
      "metadata": {
        "id": "A9mjKYis-n7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the dataset\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['comment_cleaned'], padding=\"max_length\", truncation=True)"
      ],
      "metadata": {
        "id": "KEWOTYC279Qg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizing all sets (train, validation, and test)\n",
        "tokenized_train_set = train_set.map(tokenize_function, batched=True)\n",
        "tokenized_val_set = val_set.map(tokenize_function, batched=True)\n",
        "tokenized_test_set = test_set.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "id": "6uVWitcP-oot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading BETO Model (transformer based BERT fo Spanish)\n",
        "model = BertModel.from_pretrained(\"dccuchile/bert-base-spanish-wwm-uncased\").to(device)"
      ],
      "metadata": {
        "id": "HEtuorDv-p8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    evaluation_strategy=\"epoch\",     # evaluate at the end of each epoch\n",
        "    learning_rate=2e-5,              # learning rate\n",
        "    per_device_train_batch_size=64,  # batch size for training\n",
        "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
        "    num_train_epochs=8,              # number of training epochs\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    logging_steps=10,\n",
        ")"
      ],
      "metadata": {
        "id": "kDEJRu6K8OB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for computing metrics during fine-tuning\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    # Convert logits and labels to tensors\n",
        "    logits_tensor = torch.tensor(logits)\n",
        "    labels_tensor = torch.tensor(labels)\n",
        "\n",
        "    # Compute cross entropy loss\n",
        "    loss_fct = CrossEntropyLoss()\n",
        "    loss = loss_fct(logits_tensor, labels_tensor).item()\n",
        "\n",
        "    # You can also compute accuracy or other metrics\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "\n",
        "    return {\n",
        "        'cross_entropy_loss': loss,\n",
        "        'accuracy': accuracy\n",
        "    }\n"
      ],
      "metadata": {
        "id": "YwvHGW3e81as"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating  Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,                         # BETO- pre-trained model\n",
        "    args=training_args,                  # training arguments\n",
        "    train_dataset=tokenized_train_set,   # tokenized training dataset\n",
        "    eval_dataset=tokenized_val_set,      # tokenized validation dataset\n",
        "    tokenizer=tokenizer,                 # tokenizer for BETO\n",
        "    compute_metrics=compute_metrics,     # metrics for fine-tuning evaluation\n",
        ")"
      ],
      "metadata": {
        "id": "yg6Cx4Sa87zr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tuning the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "SI6FICJz9De9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting over Test Sample"
      ],
      "metadata": {
        "id": "6Oz5T2X39VUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating test loader\n",
        "test_loader = DataLoader(tokenized_test_set, batch_size=64)"
      ],
      "metadata": {
        "id": "tXaNzkTV9Rw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_test_set.set_format(type='torch', columns=['input_ids', 'attention_mask'])"
      ],
      "metadata": {
        "id": "Islz3umR9Mz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for predictions\n",
        "def predict(model, dataloader):\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "\n",
        "            predictions.append(logits.argmax(dim=-1).cpu().numpy())\n",
        "\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "oBAGbiEk9gpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting\n",
        "predictions = predict(model, test_loader)"
      ],
      "metadata": {
        "id": "tzwC-rBQ9guH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting predictions to flat list\n",
        "predictions = [item for sublist in predictions for item in sublist]"
      ],
      "metadata": {
        "id": "ru4Li_2V9jwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding predictions to test set Dataframe\n",
        "df_test['Predicted_Label'] = predictions"
      ],
      "metadata": {
        "id": "SgUo8oEb9lxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation of test set predictions"
      ],
      "metadata": {
        "id": "p1Nm3Whd9v4J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting true labels and predicted labels form test dataframe\n",
        "y_true = df_test['label']\n",
        "y_pred = df_test['Predicted_Label']"
      ],
      "metadata": {
        "id": "qJxwYJ_39qvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating metrics\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred, pos_label=0)  # assuming 'yes'=0 is the positive class\n",
        "recall = recall_score(y_true, y_pred, pos_label=0)\n",
        "f1 = f1_score(y_true, y_pred, pos_label=0)\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "\n",
        "# Printing the metrics\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "id": "d_a990gh91l_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting over complete  data"
      ],
      "metadata": {
        "id": "CScevDEC-G4a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading complete raw data\n",
        "data_comp_df = pd.read_csv(\"Raw_Data.csv\")"
      ],
      "metadata": {
        "id": "DLPzhj4I90Ep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting datasets into Hugging Face Dataset format\n",
        "data_comp_set = Dataset.from_pandas(data_comp_df)"
      ],
      "metadata": {
        "id": "O1PfETrKCki0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizing data complete set\n",
        "tokenized_data_comp_set = data_comp_set.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "id": "h2t7KVbuClkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating data loader for data complete\n",
        "data_comp_loader = DataLoader(tokenized_data_comp_set, batch_size=64)"
      ],
      "metadata": {
        "id": "hZx5m6rB_45G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting predictions\n",
        "predictions_comp_data = predict(model, data_comp_loader)"
      ],
      "metadata": {
        "id": "4weA8yO7-iOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting predictions to flat list\n",
        "predictions_comp_data_list = [item for sublist in predictions_comp_data for item in sublist]"
      ],
      "metadata": {
        "id": "mxr-FvE4DE0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding prections to test set Dataframe\n",
        "data_comp_df['Predicted_Labels'] = predictions_comp_data_list"
      ],
      "metadata": {
        "id": "_Ec7E3s3DIfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If needed use for saving results add file name and uncomment\n",
        "#data_comp_df.to_csv(\"add_file_name.csv\")"
      ],
      "metadata": {
        "id": "f4xs11QoDNi3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}